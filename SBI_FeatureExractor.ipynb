{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwslBoPkq9qT"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Morteza-24/SelfBlendedImages.git\n",
        "!cp SelfBlendedImages/src/* ./ -r\n",
        "%pip install efficientnet-pytorch retinaface-pytorch\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model import Detector\n",
        "import torch\n",
        "\n",
        "class SBIFeatureExtractor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SBIFeatureExtractor, self).__init__()\n",
        "        sbi_model = Detector()\n",
        "        sbi_model = sbi_model.to('cuda')\n",
        "        cnn_sd = torch.load(\"drive/MyDrive/FFraw.tar\")[\"model\"]\n",
        "        sbi_model.load_state_dict(cnn_sd)\n",
        "        self.features = sbi_model.net.extract_features\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)"
      ],
      "metadata": {
        "id": "K1MnrtI-6Jz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class ConvClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_channels, num_classes=1):\n",
        "        super(ConvClassifier, self).__init__()\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(input_channels, 512, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(512, num_classes),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "H_dZ9vPOaAwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "from inference.preprocess import extract_face\n",
        "from retinaface.pre_trained_models import get_model\n",
        "\n",
        "def get_image_features(img):\n",
        "  model = SBIFeatureExtractor()\n",
        "  model.eval()\n",
        "\n",
        "  frame = cv2.imread(img)\n",
        "  frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  face_detector = get_model(\"resnet50_2020-07-20\", max_size=max(frame.shape),device=torch.device('cuda'))\n",
        "  face_detector.eval()\n",
        "\n",
        "  face_list = extract_face(frame,face_detector)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      img = torch.tensor(face_list).to(torch.device('cuda')).float()/255\n",
        "      feat = model(img)\n",
        "  return feat"
      ],
      "metadata": {
        "id": "YfUc_rcVSYdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvClassifier(input_channels=1792).to('cuda')\n",
        "features = get_image_features(\"a.png\")\n",
        "output = model(features)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "9CgjxWJ6aqv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.funcs import IoUfrom2bboxes, crop_face, RandomDownScale\n",
        "from torchmetrics.classification import BinaryAUROC\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn import functional as F\n",
        "from datetime import datetime\n",
        "import albumentations as alb\n",
        "from model import Detector\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "class SBIFeatureExtractor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SBIFeatureExtractor, self).__init__()\n",
        "        sbi_model = Detector()\n",
        "        sbi_model = sbi_model.to('cuda')\n",
        "        cnn_sd = torch.load(\"drive/MyDrive/FFraw.tar\")[\"model\"]\n",
        "        sbi_model.load_state_dict(cnn_sd)\n",
        "        self.features = sbi_model.net.extract_features\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "\n",
        "class FeatureDataset(Dataset):\n",
        "    def __init__(self, images, labels, is_val=False):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.extract_features = SBIFeatureExtractor()\n",
        "        self.extract_features.eval()\n",
        "        self.transforms = self.get_transforms()\n",
        "        self.source_transforms = self.get_source_transforms()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      flag=True\n",
        "      while flag:\n",
        "        try:\n",
        "          filename = self.images[idx]\n",
        "          img = np.array(Image.open(filename))\n",
        "          landmark = np.load(filename.replace('.png', '.npy').replace('/frames/', self.path_lm))[0]\n",
        "          bbox_lm = np.array([landmark[:,0].min(), landmark[:,1].min(), landmark[:,0].max(), landmark[:,1].max()])\n",
        "          bboxes = np.load(filename.replace('.png', '.npy').replace('/frames/', '/retina/'))[:2]\n",
        "          iou_max = -1\n",
        "          for i in range(len(bboxes)):\n",
        "            iou = IoUfrom2bboxes(bbox_lm,bboxes[i].flatten())\n",
        "            if iou_max < iou:\n",
        "              bbox = bboxes[i]\n",
        "              iou_max = iou\n",
        "          landmark = self.reorder_landmark(landmark)\n",
        "          if not self.is_val:\n",
        "            if np.random.rand() < 0.5:\n",
        "              img, _, landmark, bbox = self.hflip(img, None, landmark,bbox)\n",
        "          img,landmark,bbox,__ = crop_face(img, landmark, bbox, margin=True, crop_by_bbox=False)\n",
        "          img_r, mask = self.self_blending(img.copy(), landmark.copy())\n",
        "          if not self.is_val:\n",
        "            img_r = self.transforms(image=img_r.astype('uint8'))\n",
        "          img_f,_,__,___,y0_new,y1_new,x0_new,x1_new=crop_face(img_r,landmark,bbox,margin=False,crop_by_bbox=True,abs_coord=True,phase=\"val\" if self.is_val else \"train\")\n",
        "          img_r=img_r[y0_new:y1_new,x0_new:x1_new]\n",
        "          img_r=cv2.resize(img_r,self.image_size,interpolation=cv2.INTER_LINEAR).astype('float32')/255\n",
        "          img_r=img_r.transpose((2,0,1))\n",
        "          flag=False\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          idx=torch.randint(low=0,high=len(self),size=(1,)).item()\n",
        "      with torch.no_grad():\n",
        "        features = self.extract_features(img_r)\n",
        "      return features, self.labels[idx]\n",
        "\n",
        "    def reorder_landmark(self,landmark):\n",
        "      landmark_add = np.zeros((13,2))\n",
        "      for idx,idx_l in enumerate([77,75,76,68,69,70,71,80,72,73,79,74,78]):\n",
        "        landmark_add[idx] = landmark[idx_l]\n",
        "      landmark[68:] = landmark_add\n",
        "      return landmark\n",
        "\n",
        "    def hflip(self,img,mask=None,landmark=None,bbox=None):\n",
        "      H,W = img.shape[:2]\n",
        "      landmark = landmark.copy()\n",
        "      bbox=bbox.copy()\n",
        "      if landmark is not None:\n",
        "        landmark_new = np.zeros_like(landmark)\n",
        "        landmark_new[:17]=landmark[:17][::-1]\n",
        "        landmark_new[17:27]=landmark[17:27][::-1]\n",
        "        landmark_new[27:31]=landmark[27:31]\n",
        "        landmark_new[31:36]=landmark[31:36][::-1]\n",
        "        landmark_new[36:40]=landmark[42:46][::-1]\n",
        "        landmark_new[40:42]=landmark[46:48][::-1]\n",
        "        landmark_new[42:46]=landmark[36:40][::-1]\n",
        "        landmark_new[46:48]=landmark[40:42][::-1]\n",
        "        landmark_new[48:55]=landmark[48:55][::-1]\n",
        "        landmark_new[55:60]=landmark[55:60][::-1]\n",
        "        landmark_new[60:65]=landmark[60:65][::-1]\n",
        "        landmark_new[65:68]=landmark[65:68][::-1]\n",
        "        if len(landmark)==68:\n",
        "          pass\n",
        "        elif len(landmark)==81:\n",
        "          landmark_new[68:81]=landmark[68:81][::-1]\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "        landmark_new[:,0]=W-landmark_new[:,0]\n",
        "      else:\n",
        "        landmark_new=None\n",
        "      if bbox is not None:\n",
        "        bbox_new=np.zeros_like(bbox)\n",
        "        bbox_new[0,0]=bbox[1,0]\n",
        "        bbox_new[1,0]=bbox[0,0]\n",
        "        bbox_new[:,0]=W-bbox_new[:,0]\n",
        "        bbox_new[:,1]=bbox[:,1].copy()\n",
        "        if len(bbox)>2:\n",
        "          bbox_new[2,0]=W-bbox[3,0]\n",
        "          bbox_new[2,1]=bbox[3,1]\n",
        "          bbox_new[3,0]=W-bbox[2,0]\n",
        "          bbox_new[3,1]=bbox[2,1]\n",
        "          bbox_new[4,0]=W-bbox[4,0]\n",
        "          bbox_new[4,1]=bbox[4,1]\n",
        "          bbox_new[5,0]=W-bbox[6,0]\n",
        "          bbox_new[5,1]=bbox[6,1]\n",
        "          bbox_new[6,0]=W-bbox[5,0]\n",
        "          bbox_new[6,1]=bbox[5,1]\n",
        "      else:\n",
        "        bbox_new=None\n",
        "      if mask is not None:\n",
        "        mask=mask[:,::-1]\n",
        "      else:\n",
        "        mask=None\n",
        "      img=img[:,::-1].copy()\n",
        "      return img,mask,landmark_new,bbox_new\n",
        "\n",
        "    def self_blending(self,img,landmark):\n",
        "      H, W = len(img), len(img[0])\n",
        "      if np.random.rand() < 0.25:\n",
        "        landmark = landmark[:68]\n",
        "      if np.random.rand() < 0.5:\n",
        "        img = self.source_transforms(image=img.astype(np.uint8))['image']\n",
        "      img = img.astype(np.uint8)\n",
        "      return img\n",
        "\n",
        "    def get_transforms(self):\n",
        "      return alb.Compose([\n",
        "        alb.RGBShift((-20,20),(-20,20),(-20,20),p=0.3),\n",
        "        alb.HueSaturationValue(hue_shift_limit=(-0.3,0.3), sat_shift_limit=(-0.3,0.3), val_shift_limit=(-0.3,0.3), p=0.3),\n",
        "        alb.RandomBrightnessContrast(brightness_limit=(-0.3,0.3), contrast_limit=(-0.3,0.3), p=0.3),\n",
        "        alb.ImageCompression(quality_lower=40,quality_upper=100,p=0.5),\n",
        "      ], p=1.)\n",
        "\n",
        "    def get_source_transforms(self):\n",
        "      return alb.Compose([\n",
        "          alb.Compose([\n",
        "              alb.RGBShift((-20,20),(-20,20),(-20,20),p=0.3),\n",
        "              alb.HueSaturationValue(hue_shift_limit=(-0.3,0.3), sat_shift_limit=(-0.3,0.3), val_shift_limit=(-0.3,0.3), p=1),\n",
        "              alb.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1,0.1), p=1),\n",
        "            ],p=1),\n",
        "          alb.OneOf([\n",
        "            RandomDownScale(p=1),\n",
        "            alb.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
        "          ],p=1),\n",
        "        ], p=1.)\n",
        "\n",
        "\n",
        "class ConvClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_channels, num_classes=1):\n",
        "        super(ConvClassifier, self).__init__()\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(input_channels, 512, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(512, num_classes),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "with open(\"configs/sbi/base.json\", \"rt\") as f:\n",
        "  cfg = json.load(f)\n",
        "train_dataset = FeatureDataset(train_images, train_labels)\n",
        "val_dataset = FeatureDataset(val_images, val_labels, is_val=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=cfg['batch_size'] // 2,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=8,\n",
        "                                           pin_memory=True,\n",
        "                                           drop_last=True,\n",
        "                                           persistent_workers=True\n",
        ")\n",
        "val_loader=torch.utils.data.DataLoader(val_dataset,\n",
        "                                       batch_size=cfg['batch_size'],\n",
        "                                       shuffle=False,\n",
        "                                       num_workers=8,\n",
        "                                       pin_memory=True,\n",
        "                                       persistent_workers=True\n",
        ")\n",
        "model = ConvClassifier(input_channels=1792).to('cuda')\n",
        "criterion = torch.nn.BCEWithLogitsLoss()  # Combines sigmoid + binary cross-entropy\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.75)\n",
        "train_auc_metric = BinaryAUROC(thresholds=None).to('cuda')\n",
        "val_auc_metric = BinaryAUROC(thresholds=None).to('cuda')\n",
        "now = datetime.now()\n",
        "save_path = 'output/{}_'.format(\"SBI_FE_\")+'base'+'_'+now.strftime(\"%m_%d_%H_%M_%S\")+'/'\n",
        "weight_dict = {}\n",
        "\n",
        "for epoch in range(cfg[\"epoch\"]):\n",
        "    print(f\"Epoch {epoch + 1}/{cfg[\"epoch\"]}\")\n",
        "    print(\"-\" * 30)\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "\n",
        "    for features, labels in train_loader:\n",
        "        features, labels = features.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track loss and accuracy\n",
        "        running_loss += loss.item() * features.size(0)  # Accumulate loss\n",
        "        preds = (outputs > 0.5).float()  # Threshold for binary classification\n",
        "        correct_preds += (preds == labels).sum().item()\n",
        "        total_preds += labels.size(0)\n",
        "        train_auc_metric.update(outputs.sigmoid(), labels.int())\n",
        "\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_accuracy = correct_preds / total_preds\n",
        "    train_auc = train_auc_metric.compute().item()\n",
        "    train_auc_metric.reset()\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Train AUC: {train_auc:.4f}\")\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct_preds = 0\n",
        "    val_total_preds = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, labels in val_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Track loss and accuracy\n",
        "            val_loss += loss.item() * features.size(0)  # Accumulate loss\n",
        "            preds = (outputs > 0.5).float()\n",
        "            val_correct_preds += (preds == labels).sum().item()\n",
        "            val_total_preds += labels.size(0)\n",
        "            val_auc_metric.update(outputs.sigmoid(), labels.int())\n",
        "\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    val_accuracy = val_correct_preds / val_total_preds\n",
        "    val_auc = val_auc_metric.compute().item()\n",
        "    val_auc_metric.reset()\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Validation AUC: {val_auc:.4f}\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if len(val_auc_list) < 6:\n",
        "      save_model_path=os.path.join(save_path+'weights/',\"{}_{:.4f}_val.tar\".format(epoch+1, val_auc))\n",
        "      weight_dict[save_model_path] = val_auc\n",
        "      torch.save({\n",
        "          \"model\":model.state_dict(),\n",
        "          \"optimizer\":model.optimizer.state_dict(),\n",
        "          \"epoch\":epoch\n",
        "      },save_model_path)\n",
        "      last_val_auc = min([weight_dict[k] for k in weight_dict])\n",
        "    elif val_auc >= last_val_auc:\n",
        "      save_model_path = os.path.join(save_path+'weights/',\"{}_{:.4f}_val.tar\".format(epoch+1,val_auc))\n",
        "      for k in weight_dict:\n",
        "        if weight_dict[k] == last_val_auc:\n",
        "          del weight_dict[k]\n",
        "          os.remove(k)\n",
        "          weight_dict[save_model_path] = val_auc\n",
        "          break\n",
        "      torch.save({\n",
        "          \"model\":model.state_dict(),\n",
        "          \"optimizer\":model.optimizer.state_dict(),\n",
        "          \"epoch\":epoch\n",
        "      },save_model_path)\n",
        "      last_val_auc = min([weight_dict[k] for k in weight_dict])\n",
        "    print()\n",
        "\n",
        "print(\"Training Complete!\")"
      ],
      "metadata": {
        "id": "QM7FQH5XgYtc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}